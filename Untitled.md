我觉得难点不一定是一个很难的技术点吧，我们日常的项目都是crud项目，其实真正很难的地方很少，都有相关的解决方案。像我的话我会说一些项目的核心功能的实现，尽量往原理方向看齐，然后就是一些优化，以及为什么要这样优化。更多的还是体现在项目中的思考以及技术上的成长，回答的逻辑，这个也在我之后反问环节里面试官的回答中验证过

### java文件如何转成class文件

![img](https://img2018.cnblogs.com/blog/1329031/201901/1329031-20190128142848684-959620106.png)

- 词法分析：读取源代码，一个字节一个字节的读进来，找出这些词法中我们定义的语言关键词如：if、else、while等，识别哪些if是合法的哪些是不合法的。
- 语法分析：就是对词法分析中得到的token流进行语法分析，这一步就是检查这些关键词组合在一起是不是符合Java语言规范。如if的后面是不是紧跟着一个布尔型判断表达式。
- 语义分析：语义分析的主要工作就是把一些难懂的，复杂的语法转化成更简单的语法。将复杂的语法转化为简单的语法，对应到Java就是将foreach转化为for循环，还有一些注释等。
- 字节码生成：将会根据经过注释的抽象语法树生成字节码，也就是将一个数据结构转化为另外一个数据结构。

### 堆上的元素满了会发生什么？

### 发生了OOM，应该怎么去分析解决？jvm调优

- java堆溢出：通过Eclipse Memory Analyzer分析OOM的dump的内存快照可以得出，到底是由于程序原因导致的内存泄露，还是没有估计好JVM内存的大小而导致的内存溢出。**JVM的堆参数：-Xms：初始堆大小；-Xmx：最大堆大小；-Xmn：年轻代大小**
- 栈溢出：StackOverflowError。**JVM参数：-Xss: 每个线程的堆栈大小,JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K.**
- 运行时常量池溢出：java.lang.OutofMemoryError: PermGen space。**JVM参数：-XX:PermSize：设置持久代(perm gen)初始值，默认值为物理内存的1/64；-XX:MaxPermSize：设置持久代最大值，默认为物理内存的1/4**

### new一个对象，引用放在哪？基本数据类型的数据会放在哪？

基本数据类型和引用主要看在哪里声明，方法中声明，说明是局部变量，放在栈区；类中声明，说明是成员变量，全局变量，放在堆中

### 如果一个页面迟迟不响应，一直在创建线程，线程池满了。怎么办？

会造成资源耗尽，抛出内存溢出异常，JVM中能创建的线程数是有限制的。计算公式：

`(MaxProcessMemory - JVMMemory - ReservedOsMemory) / (ThreadStackSize)`

MaxProcessMemory ：指的是一个进程的最大内存

JVMMemory ：JVM内存

ReservedOsMemory ：保留的操作系统内存

ThreadStackSize ：线程栈的大小

因此**给JVM内存越大，能创建的操作系统线程数量越少**，越容易发生溢出。因此如果确实需要大量线程，可以调整MaxProcessMemory，JVMMemory，ThreadStackSize。减少JVM内存大小（Xmx参数）、减小线程的栈大小(调整Xss参数)

### 数据库的乐观锁悲观锁咋实现？

乐观锁：大多数基于数据版本（Version）记录机制实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断当前版本信息与第一次取出来的版本值大小，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据，拒绝更新，让用户重新操作。

```sql
 //查询商品的名称，状态以及该信息的版本号字段
 select (name,status,version) from t_goods where id =#{id}
 //修改商品中状态为2
 update t_goods set status =2 .version =version+1 where id =#{id} and version =#{version}
```

悲观锁：for update

### linux命令

#### 查看磁盘空间：统计磁盘整体情况，包括磁盘大小，已使用，可用。命令“df”

命令"df -lh"使用这个命令会更清楚磁盘使用情况

命令"df -a"是全部的文件系统的使用情况

#### 查看文件前几行和后几行

```shell
head -n 10 /etc/profile  //查看前10行
tail -n 10 /etc/profile //查看后10行
head -n 10 /etc/profile >>/home/test //内容输出到test中
```

#### 查询指定内容的上下文

```shell
grep -C 10 keyword catalina.out 显示file文件中匹配keyword字串那行以及上下10行
grep -B 10 keyword catalina.out 显示keyword及前10行
grep -A 10 keyword catalina.out 显示keyword及后10行
grep -C 10 keyword catalina.out  > aaa.txt  重定向到aaa.txt
grep -o keyword catalina.out | wc -l 统计包含某个关键字的个数
```

#### 查看进程资源使用情况

`top [-d number] | top [-bnp]`

-d：number代表秒数，表示top命令显示的页面更新一次的间隔。默认是5秒。 -b：以批次的方式执行top。 -n：与-b配合使用，表示需要进行几次top命令的输出结果。 -p：指定特定的pid进程号进行观察。

![image-20200910094357659](D:\Typora\picture\image-20200910094357659.png)

第一行是任务队列信息，包括当前时间，系统运行时间，当前登录用户数，系统负载（即任务队列的平均长度）

第二行是进程的信息，包括进程总数，正在运行的进程数，睡眠的进程数，停止的进程数，僵尸进程数

第三行是CPU信息，包括用户空间占用cpu百分比，内核空间占用cpu百分比等等

第四行是内存信息，包括物理内存总量，空闲内存总量，使用的物理内存总量等等。

第五行是swap交换区信息，包括交换区总量，使用的交换区总量，空闲的交换区总量等等

![image-20200910095115791](D:\Typora\picture\image-20200910095115791.png)

接下来就是一些进程信息

#### netstat

列出所有端口 (包括监听和未监听的)

```shell
netstat -a     #列出所有端口
netstat -at    #列出所有tcp端口
netstat -au    #列出所有udp端口    
```

列出所有处于监听状态的 Sockets

```shell
netstat -l        #只显示监听端口
netstat -lt       #只列出所有监听 tcp 端口
netstat -lu       #只列出所有监听 udp 端口
netstat -lx       #只列出所有监听 UNIX 端口
```

显示每个协议的统计信息

```shell
netstat -s   显示所有端口的统计信息
netstat -st   显示TCP端口的统计信息
netstat -su   显示UDP端口的统计信息
```

找出运行在指定端口的进程

```shell
netstat -an | grep ':80'
```



#### 统计文件中hello出现的次数

用vim打开，然后输入`:%s/hello//gn`

`:%1,3s/hello//gn`1~3行出现的hello

使用命令行：`grep -o "hello" hello.log | wc -l`

### 网站访问反应慢，会是什么原因

1. 可能是客户端的问题，自己访问试一试，排除客户端问题
2. 服务器出口带宽不够用
3. 服务器负载过大，反应不过来。可使用top命令查看CPU，内存占用情况。如果二者都正常，再使用sar命令分析网卡流量，分析是不是遭到攻击。
4. 数据库瓶颈，比如慢查询比较多，那么可以SQL优化；如果响应慢，可考虑加缓存或者搭建数据库主从

### comparator和comparable的区别

Comparable是**内部比较器**（即用于实现了Comparable接口的类与自身进行比较），称自然排序；位于包java.lang下。Comparable接口将比较代码嵌入自身类中

Comparator位于包java.util下，在一个独立的类中实现比较，是一种外部比较器，一般是这个类没有实现Comparable接口，或者对已有的Comparable接口不满意想自己重写比较方式的时候使用。

### 内存泄漏场景

- **静态集合类**：如果这些容器为静态的，那么它们的生命周期与程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。
- **各种连接，如数据库连接、网络连接和IO连接等**：不再使用的时候没有close关闭
- **变量不合理的作用域**：一个变量的定义的作用范围大于其使用范围，很有可能会造成内存泄漏。另一方面，如果没有及时地把对象设置为null，很有可能导致内存泄漏的发生。
- **内部类持有外部类**：如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。
- **改变哈希值**：当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则找不到这个对象，导致无法从集合中删除，造成内存泄漏

### String为什么设计为final?

主要是安全性。首先final修饰String类，代表String不可被继承，并且private final还修饰String类中的value数组，这两者保证了final的不可变性！不能被继承避免了因为继承引起的安全隐患。而且很多地方都会使用到字符串。

为了实现字符串池，可以让不同字符变量都指向池中同一个字符串。

由于String不可变，它的hashcode创建的时候就被缓存了，很适合作为map的键

### toString()和String.valueOf

相同点：

- Object类中有toString()，因此任何一个对象都能调用toString
- valueOf的参数是Object，可以传入任何一个对象
- 返回类型都是String

不同点：

- 对象为null时，toString报错
- 对象为null时，String.valueOf返回null字符串

### 为什么新生代是1/3？

### jvm执行引擎是什么？

### jvm控制台命令？比如查看虚拟机进程情况，监控某个进程java堆情况

- jps：显示当前所有java进程pid的命令
- jmap：jmap -head <java进程pid> 查看堆使用情况
- jstat：可以查看堆内存各部分的使用量，以及加载类的数量。比如：
  - jstat -class \<pid>：类加载统计
  - jstat -gc \<pid>：垃圾回收统计
  - jstat -gcnew \<pid>：新生代垃圾回收统计
- jstack：可以查看或导出java线程堆栈信息，尤其是他可以用来生成thread dump文件，这个文件记录了某一时刻CPU信息，因此调优的时候需要多份文件来对比分析

所以遇到频繁GC或者内存溢出问题时：

1. 使用jps查看线程ID
2. 使用jstat -gc查看gc情况
3. 使用jmap -dump:format=b,file=heapDump \<pid>生成堆转储文件
4. 使用jhat或可视工具分析堆情况

死锁问题：

1. 使用jps查看线程ID
2. 使用jstack \<pid> 查看线程情况

### 为什么不可以四次握手？

一开始设计的时候，第二次握手server发送ack，第三次握手server发送syn，第四次握手client发送ack

这第二次和第三次合并为第二次，就成了三次握手。

那为什么不能两次握手，因为SYN这个同步标志位是一个占用一个字节的编号（FIN也是），因此根据TCP设计原则，对有数据的TCP segment 必须确认的原则。因此client 必须给server一个确认

### SYN攻击

利用了这个TCP三次握手的特性。

A（攻击者）发送TCP SYN，SYN是TCP三次握手中的第一个数据包，而当这个服务器返回ACK以后，**A不再进行确认**，那这个连接就处在了一个挂起的状态，也就是**半连接**的意思**（内核有半连接队列）**，那么服务器收不到再确认的一个消息，还会重复发送ACK给A。浪费服务器的资源。A就对服务器发送非法大量的这种TCP连接，由于每一个都没法完成握手的机制，所以它就会消耗服务器的内存最后可能导致服务器死机，就无法正常工作了。

防范：其实最常用的一个手段就是优化主机系统设置。比如降低SYN timeout时间，使得主机尽快释放半连接的占用或者采用SYN cookie设置，如果短时间内收到了某个IP的重复SYN请求，我们就认为受到了攻击。我们合理的采用防火墙设置等外部网络也可以进行拦截。

### UDP如何实现可靠传输？

只能通过应用层来实现，实现确认机制、重传机制、窗口确认机制；比如有如下开源程序利用udp实现了可靠的数据传输。分别为RUDP、RTP、UDT

或者QUIC协议

### 一致性Hash

比如Redis集群的时候，一共4台服务器，每台服务器存的key是不同的，我们通过hash算法（hash(key)%4）得知当前key在哪一台服务器上，但是如果服务器增加或者减少，hash结果都会改变，这样是不行的，因此使用一致性hash算法

一致性Hash也是使用取模，但是之前是用服务器数量取模，而一致性hash是对2^32取模，就是说如果假设哈希函数取值范围是32位无符号整型0~2^32-1，可以看作是一个虚拟的Hash圆环。将各个服务器的IP地址或者主机名作为关键字进行Hash，得到每台机器在环上的位置（绿点），之后把key用相同的Hash函数算出哈希值，确定数据位置（黄点），然后沿着环顺时针行走，第一台遇到的服务器就是目标服务器。

现在假如NodeC宕机了，可知A、B、D不会受影响，就是C被重定向到了NodeD，一般一致性Hash中，一台服务器不可用影响的只是此服务器到其环空间前一台服务器之间的数据

同样我们也可以想象，如果新增一台服务器，影响的也只是新增的服务器到其环空间前一台服务器之间的数据。因此一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

![img](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/UtWdDgynLdbhiae1AfNYAibdp7ib2wTZTrppjapqr7nD1s7BeSGmJKMichyiaQJrIqtatg5WibKY4yYc0bdJjrticu73g/640)

**存在的问题**

当结点太少的时候，Hash环存在数据倾斜的情况

![img](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/UtWdDgynLdbhiae1AfNYAibdp7ib2wTZTrp9PHNl5KgHfujn5WQzr3sXwccleFsbhRfUdKuc3JHiafHB25SJ6ng5aQ/640)

为了解决这种问题，一致性Hash引入**虚拟节点**的机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。比如上面的情况，为每台服务器计算三个虚拟节点，形成六个虚拟节点。

![img](https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/UtWdDgynLdbhiae1AfNYAibdp7ib2wTZTrpnNGzjcWYy3ylL7s1Bq2UKicU5mYG8SHsuIFTOf2PMe2FstpM2gMeQbw/640)

同时数据定位算法不变，只是**多了一步虚拟节点到实际节点的映射**，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

### jvm堆的划分？

根据对象存活的周期不同，把堆内存划分为几块，一般分为新生代、老年代和永久代

### Lock底层实现

int状态位+双向链表+CAS自旋

https://blog.csdn.net/qq_29373285/article/details/85964460

### Mysql怎么实现乐观锁和悲观锁

乐观锁常见的就是增加version字段或时间戳字段，每次修改都进行这个字段的更新。

悲观锁是使用select…for update。MySQL InnoDB默认Row-Level Lock，所以只有「明确」地指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住)。

### Rand5生成Rand7

先产生一个均匀分布的 0， 5， 10， 15， 20的数，再产生一个均匀分布的 0， 1， 2， 3， 4 的数。相加以后，会产生一个 0到24的数，而且每个数（除0外）生成的概率是一样的。我们只取 1 - 21 这一段，和7 取余以后+1就能得到完全均匀分布的1-7的随机数了。

```c++
int Rand5()
{
    int m = rand() % 5 + 1;
    return m;
}

int Rand7()
{
    int x = 22;
    while (x > 21)
        x = Rand5() + (Rand5() - 1) * 5;
    return x % 7 + 1;
}
```

### Spring注解实现原理？

### Spring事务传播机制？

https://segmentfault.com/a/1190000013341344

| 事务传播行为类型          | 说明                                                         |
| ------------------------- | ------------------------------------------------------------ |
| PROPAGATION_REQUIRED      | 如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。 |
| PROPAGATION_SUPPORTS      | 支持当前事务，如果当前没有事务，就以非事务方式执行。         |
| PROPAGATION_MANDATORY     | 使用当前的事务，如果当前没有事务，就抛出异常。               |
| PROPAGATION_REQUIRES_NEW  | 新建事务，如果当前存在事务，把当前事务挂起。                 |
| PROPAGATION_NOT_SUPPORTED | 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。   |
| PROPAGATION_NEVER         | 以非事务方式执行，如果当前存在事务，则抛出异常。             |
| PROPAGATION_NESTED        | 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。 |

### Stream类?

### MySQL分库分表？

### MySQL一条语句执行慢的原因？

#### 大多数情况正常，偶尔很慢

- 数据库在刷新脏页。脏页就是记录到redo log日记中，但还来不及同步到磁盘中。当数据库一直很忙，redo log写满了，就会没办法等空闲的时候在数据同步磁盘，只能暂停其他操作。
- 拿不到锁。

#### 一直都这么慢

- 没用到索引。包括没有设置索引和没用上索引，比如函数操作
- 有时候系统会判断全表扫描好还是走索引好，可能判断失误走了全表，它选错索引。

### MySQL执行过程？

![img](https://user-gold-cdn.xitu.io/2018/12/28/167f4c7b99f87e1c?imageslim)

MySQL主要分为Server层和引擎层，Server层主要包括连接器（权限检查作用）、查询缓存（8.0以前）、分析器、优化器、执行器。同时还有一个日志模块（binlog），这个日志模块所有引擎都可共用，redolog只有InnoDB使用。

SQL执行过程分为两类：

- 对于查询等过程如下：权限校验—>查询缓存—>分析器—>优化器—>权限校验—>执行器—>引擎
- 对于更新等语句执行流程如下：分析器---->权限校验---->执行器—>引擎—redo log prepare—>binlog—>redo log commit

**<font color='green'>补充redolog和binlog：</font>**

redolog是两阶段提交的。在更新语句的时候，InnoDB引擎会先写入redolog，此时redolog进入预提交状态，然后通知执行器记录binlog，调用引擎接口，提交redolog为提交状态。

两阶段提交主要是为了数据一致性。只有在redolog预提交，binlog也写完这时候宕机会发生不一致的问题，这时候MySQL处理过程是：

1. 判断redolog是否完整，如果完整，就立即提交。
2. 如果redolog只是预提交但不是commit状态，这个时候判断binlog是否完整，完整就提交redolog，否则回滚事务

### MySQL的锁？

共享(S)/排它(X)锁、Record Locks、间隙锁、Next-key Locks

### MySQL查询正在执行的进程？

启动mysql，输入show processlist;

### MySQL死锁怎么解决，怎么选择结束哪个事务

MySQL的Innodb会主动探知到死锁，提供了wait-for graph算法来主动进行死锁检测，每当加锁请求无法立即满足需要进入等待时，wait-for graph算法都会被触发。这个算法就是把每个事务看成一个个结点，当事务1需要等待事务2的锁，就生成有向边1->2，最后看看会不会成环

Innodb目前处理死锁的方法就是将**持有最少行级排他锁**的事务进行**回滚**。

如何减少死锁：

1. 使用事务，不使用 lock tables 。
2. 保证没有长事务。
3. 操作完之后立即提交事务，特别是在交互式命令行中。
4. 如果在用 (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)，尝试降低隔离级别。
5. 修改多个表或者多个行的时候，将修改的顺序保持一致。
6. 创建索引，可以使创建的锁更少。
7. 最好不要用 (SELECT ... FOR UPDATE or SELECT ... LOCK IN SHARE MODE)。

### 如何设计一个高并发系统，哪些角度？

- 系统拆分
- 缓存
- MQ
- 分库分表
- 读写分离

### 脑裂？

### 自定义类加载器的应用场景

- **加密**：如果你不想自己的代码被反编译的话。（类加密后就不能再用ClassLoader进行加载了，这时需要自定义一个类加载器先对类进行解密，再加载）。
- **从非标准的来源加载代码**：如果你的字节码存放在数据库甚至是云端，就需要自定义类加载器，从指定来源加载类。

### select、poll、epoll区别

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 

- select仅仅知道有IO时间发生，无差别**轮询**所有的流（通过把**数组**从用户态拷贝到内核态），找出能读出数据或者写入数据的流，然后对他们进行操作，时间复杂度是O(n)，
- poll本质和select没有差别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的状态，但是**它没有最大连接数的限制**，因为它使用**链表存储**，时间复杂度也是O(n)
- epoll是事件驱动IO（每个事件关联上fd），epoll会把哪个流发生了怎样的I/O事件**通知应用程序**。复杂度降低到O(1)。它的操作方式是**回调**，底层实现是**红黑树**，它是事件通知方式，每当有描述符就绪，系统注册的回调函数就会被调用，把就绪的描述符放入Ready队列，因此它只遍历活跃的描述符。因此它也是需要轮询就绪链表，只不过select和poll需要遍历一遍，而eopll只要判断链表是否为空即可，因为这是描述符自己加入进来的，肯定就绪。
  - Edge_triggered(边缘触发)：当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它还会**通知你在上没读写完的文件描述符上继续读写**，当然如果你一直不去读写，**它会一直通知你**如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。
  - Level_triggered(水平触发)：当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它**不会通知你没读写完的文件描述符**，也就是**它只会通知你一次**，直到该文件描述符上出现第二次可读写事件才会通知你！这种模式比水平触发**效率高**，系统不会充斥大量你不关心的就绪文件描述符！

### **2GB内存中，给40亿个不重复的无符号整数，没排过序，给一个无符号整数如何快速判断这个数是否在这40亿个数中**

使用bitmap，每个int32位，可以表示32个整数，因此建立int数组temp[1+N/32];

![img](https://img-blog.csdnimg.cn/20190812210832756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MjY5OTg4,size_16,color_FFFFFF,t_70)

通过直接除以32取整数部分判断数字位于哪个数组下标，然后mod32确定在哪个位





### 1000瓶水其中有一瓶水有毒，有10只老鼠并且只要老鼠喝了有毒的水必死。请问怎样通过一次实验找出有毒的那瓶水。

用二进制，

| 第9位         | 第8位 | 第7位 | 第6位 | 第5位 | 第4位 | 第3位 | 第2位 | 第1位 | 第0位 | 水的编号 |
| ------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -------- |
| 0             | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0        |
| 0             | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 1     | 1        |
| 0             | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 1     | 0     | 2        |
| 0             | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 1     | 1     | 3        |
| 0             | 0     | 0     | 0     | 0     | 0     | 0     | 1     | 0     | 0     | 4        |
| ***\. . .\*** |       |       |       |       |       |       |       |       |       |          |
| 1             | 1     | 1     | 1     | 1     | 0     | 0     | 1     | 1     | 0     | 998      |
| 1             | 1     | 1     | 1     | 1     | 0     | 0     | 1     | 1     | 1     | 999      |

10只老鼠分别喝对应位为1的水，死的老鼠对应位置1，结果就是水的编号

## Mysql如何实现事务的？

事务：是数据库操作的最小工作单元，是作为单个逻辑工作单元执行的一系列操作；这些操作作为一个整体一起向系统提交，要么都执行、要么都不执行；事务是一组不可再分割的操作集合；

三个技术：日志文件（redo log和undo log）、锁、MVCC

### 日志文件

- redo log：叫做**重做日志**，用来实现事务的持久性，存在磁盘中，事务提交后的修改信息都会存到该日志中。每次都是先存到缓存里面，然后后台线程把缓存和日志文件同步，如果还没来得及同步那就丢失这部分已提交事务的修改信息。所以**<font color='cornflowerblue'>redo log是用来恢复数据的 用于保障，已提交事务的持久化特性。</font>**
- undo log：叫做**回滚日志**，用于记录数据被修改前的信息。undo log 记录事务修改之前版本的数据信息。所以**<font color='cornflowerblue'>undo log是用来回滚数据的用于保障 未提交事务的原子性。</font>**

### 锁

- 共享锁：读锁
- 排他锁：写锁

**<font color='cornflowerblue'>事务的隔离性就是通过读写锁+MVCC来实现的</font>**

### MVCC

多版本并发控制

> InnoDB的 MVCC ，是通过在每行记录的后面保存两个隐藏的列来实现的。这两个列，
> 一个保存了行的**创建时间**，一个保存了行的**过期时间**，
> 当然存储的并不是实际的时间值，而是系统版本号。

他的主要实现思想是通过**数据多版本**来做到**读写分离**。从而实现不加锁读进而做到读写并行。

**MVCC在mysql中的实现依赖的是undo log与read view**

- read view：用来判断当前版本数据的可见性



### 如何实现事务？

前面说了原子性、隔离性、持久性的实现

那么**<font color='cornflowerblue'>一致性是通过原子性，持久性，隔离性来实现的</font>**

- <font color='red'>原子性</font>：

事务里面发生异常了就通过undo log回滚，每条数据变更(insert/update/delete)操作都伴随一条undo log的生成，并且**回滚日志必须先于数据持久化到磁盘上**。回滚就是根据回滚日志做逆向操作，比如delete的逆向操作为insert，insert的逆向操作为delete，update的逆向为update等。

![img](https://user-gold-cdn.xitu.io/2019/4/18/16a2fe331bab111c?w=4652&h=1848&f=png&s=867671)

回滚就执行undo log里面的语句呗

- <font color='red'>持久性</font>：

Mysql的数据是存储在磁盘当中的，为了提升性能Innodb提供了**缓冲池**，读数据的时候先读缓存，如果没有就从磁盘读然后放入缓存；写数据先写入缓存，定期同步到磁盘。

当我们修改的时候，写完内存了，但数据还没真正写到磁盘的时候。此时我们的数据库挂了，我们可以根据`redo log`来对数据进行恢复。

**<font color='green'>补充一下</font>**：这里还有个log叫做binlog，它和redo log很像，不过binlog记录的是每次的sql语句，redo log记录的是物理修改内容（xxxx页修改了xxx）。`redo log` 记录的是数据的**物理变化**，`binlog` 记录的是数据的**逻辑变化**。

`binlog`的作用是**复制和恢复**：主从服务器需要保持数据的一致性，通过`binlog`来同步数据。如果整个数据库的数据都被删除了，`binlog`存储着所有的数据变更情况，那么可以通过`binlog`来对数据进行恢复。

但是redolog就不能恢复数据库记录了，`redo log` 存储的是物理数据的变更，如果我们内存的数据已经刷到了磁盘了，那`redo log`的数据就无效了。所以`redo log`不会存储着**历史**所有数据的变更，**文件的内容会被覆盖的**。

redo log何时产生的？

![img](https://user-gold-cdn.xitu.io/2019/4/17/16a26f9acf011739?w=994&h=373&f=png&s=120202)

redo log也需要存储，为何磁盘IO还用？

一是redo log 的存储是顺序存储，而缓存同步是随机操作。因此顺序IO快于随机IO。二是缓存同步是以数据页为单位的，每次传输的数据大小大于redo log。



- <font color='red'>隔离性</font>：

前面的持久性和原子性是为了实现数据的可靠性保障，**隔离性是要管理多个并发读写请求的访问顺序**

一个一个隔离级别来看

1. **READ UNCOMMITED** (未提交读)

   读写并行，性能高，脏读。

   读的操作不能排斥写请求。

   ![img](https://user-gold-cdn.xitu.io/2019/4/18/16a2ed4dbd348a68?w=4284&h=1288&f=png&s=731191)

2. **READ COMMITED** (提交读)

   InnoDB在READ COMMITTED，使用排它锁,读取数据不加锁而是使用了MVCC机制（读取快照）。或者换句话说他采用了**读写分离机制**。

   不可重复读以及幻读的问题

   <font color='green'>为什么会不可重复读？</font>

   这跟 READ COMMITTED 级别下的MVCC机制有关系，在该隔离级别下每次 select的时候新**生成一个版本号**，所以每次select的时候**读的不是一个副本而是不同的副本**。每次select产生不同的Read View

   ![img](https://user-gold-cdn.xitu.io/2019/4/18/16a2f05d63f388d0?w=3612&h=1512&f=png&s=816439)

3. **REPEATABLE READ** (可重复读)

   mysql 有两种机制可以达到这种隔离级别的效果，分别是采用读写锁以及MVCC。

   **采用读写锁实现**

   ![img](https://user-gold-cdn.xitu.io/2019/4/18/16a2c351eb03fc24?w=1082&h=290&f=png&s=120400)

   只要没释放读锁，再次读的时候还是可以读到第一次读的数据。<font color='red'>无法做到读写并行</font>

   **采用MVCC实现**

   ![img](https://user-gold-cdn.xitu.io/2019/4/18/16a2f054474b394b?w=3584&h=1512&f=png&s=756027)

   多次读取只生成一个版本，同一个Read View，select的时候不再生成新的。读到的自然是相同数据。

4. **SERIALIZABLE** (串行化)

![img](https://user-gold-cdn.xitu.io/2019/4/18/16a2f56d34ff739e?w=3528&h=1060&f=png&s=414467)

## 如何防止SQL注入

sql注入只对sql语句编译过程有破坏作用

select admin from user where username=？ And password=?

使用预编译Sql语句，变量使用？表示，username 变量传递的'admin' or 'a'='a' 参数， 也只会当作 username 字符串来解释查询。

mybatis时#{}方式可以防止sql注入，它是占位符，预编译处理，调用PreparedStatement的set方法来赋值。；${}不能防止，它是拼接符，字符串替换，没有预编译处理

还可以通过过滤传进来的参数

## Java的缓存（JVM缓存）

## MySQL insert的锁

https://www.aneasystone.com/archives/2017/11/solving-dead-locks-two.html

https://www.aneasystone.com/archives/2017/12/solving-dead-locks-three.html

## 开根号（保留小数）

## HTTPS的ssl握手

client和server首先交流ssl版本等信息

server发送公钥证书给client，这个证书是通过CA认证的（用CA的私钥加密）

client用这个公钥加密一个密钥发送给server，这个密钥就是他们之后通信加密的密钥，这里是一个非对称加密过程

通过对称加密通信。

## 图的分类

有向图、无向图、完全无向图（任意两个顶点之间都存在边）、完全有向图（任意两个顶点之间都存在方向互为相反的两条弧）

## Wait()的底层原理

wait即object的wait()和notify()或者notifyall()一起搭配使用
wait方法会将当前线程放入wait set等待被唤醒

1.将当前线程封装成objectwaiter对象node
2.通过objectmonitor::addwaiter方法将node添加到_WaitSet列表中
3.通过ObjectMonitor:exit方法释放当前的ObjectMonitor对象（释放锁），这样其他竞争线程就可以获取该ObjectMonitor对象
4.最终底层的**park**方法会挂起线程
notify方法就是随机唤醒等待池中的一个线程

## JVM跑多少线程不会发生OOM

有一个计算公式：

`(MaxProcessMemory - JVMMemory - ReservedOsMemory) / (ThreadStackSize) = Number of threads`

MaxProcessMemory     指的是一个进程的最大内存
JVMMemory            JVM内存
ReservedOsMemory     保留的操作系统内存
ThreadStackSize      线程栈的大小

Java中，当你创建一个线程的时候，虚拟机会在JVM内存创建一个Thread对象同时创建一个操作系统线程，

而这个系统线程的内存用的不是JVMMemory，而是系统中剩下的内存(MaxProcessMemory - JVMMemory - ReservedOsMemory)。

由公式得出结论：你给JVM内存越多，那么你能创建的线程越少，

## java反射Class.forName和ClassLoader的区别

Class.forName加载类时（默认）将类进了初始化，而ClassLoader的loadClass并没有对类进行初始化，只是把类加载到了虚拟机中。

## 从计算机层面开始说一下一个索引数据加载的流程

计算机的数据加载是通过磁盘IO，磁盘读取数据靠的是机械运动，每一次读取数据需要**寻道、寻点、拷贝到内存**三步操作。前两步骤比较耗时，最后有一步很快，总共一次IO差不多9ms

计算机操作系统做了**预读**的优化，当一次IO时，不光把当前磁盘地址的数据，而是把**相邻的数据**也都读取到内存缓冲区内。每一次IO读取的数据我们称之为一页(page)，具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO。

那我们想要优化数据库查询，就要**尽量减少磁盘的IO操作**，所以就出现了索引。

那么相当于B+树一个结点就是一个页，那么使用B+树的好处就是可以把树的高度压的很扁，因为一次一页能够读进来更多的信息，而B树还包括了数据信息，没用。

## binlog的格式

### Statement

每一条会修改数据的sql都会记录在binlog中

**优点**：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。(相比row能节约多少性能与日志量，这个取决于应用的SQL情况，正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，但是考虑到如果带条件的update操作，以及整表删除，alter表等操作，ROW格式会产生大量日志，因此在考虑是否使用ROW格式日志时应该跟据应用的实际情况，其所产生的日志量会增加多少，以及带来的IO性能问题。)

**缺点**：由于记录的**只是执行语句**，为了这些语句能在slave上正确运行，因此**还必须记录每条语句在执行的时候的一些相关信息**，以保证所有语句能在slave得到和在master端执行时候相同的结果。另外mysql 的复制,像一些特定函数功能，slave可与master上要保持一致会有很多相关问题(如sleep()函数， last_insert_id()，以及user-defined functions(udf)会出现问题).

### Row

不记录sql语句上下文相关信息，仅保存哪条记录被修改。

**优点**： binlog中可以**不记录执行的sql语句的上下文相关的信息**，仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题

**缺点**：所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会**产生大量的日志内容**，比如一条update语句，修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中。

### Mixedlevel

是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。


## ASCII、Unicode和UTF-8编码的区别？

**ASCII**

ASCII 只有127个字符，表示英文字母的大小写、数字和一些符号，但由于其他语言用ASCII 编码表示字节不够，例如：常用中文需要两个字节，且不能和ASCII冲突，中国定制了GB2312编码格式，相同的，其他国家的语言也有属于自己的编码格式

**Unicode**

由于每个国家的语言都有属于自己的编码格式，在多语言编辑文本中会出现乱码，这样Unicode应运而生，Unicode就是将这些语言统一到一套编码格式中，通常两个字节表示一个字符，而ASCII是一个字节表示一个字符，这样如果你编译的文本是全英文的，用Unicode编码比ASCII编码需要多一倍的存储空间，在存储和传输上就十分不划算

**UTF-8**

为了解决上述问题，又出现了把Unicode编码转化为“**可变长编码**”UTF-8编码，UTF-8编码将Unicode字符按数字大小编码为1-6个字节，英文字母被编码成一个字节，常用汉字被编码成三个字节，如果你编译的文本是纯英文的，那么用UTF-8就会非常节省空间，并且ASCII码也是UTF-8的一部分

(1) 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。

(2)用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件。

## 原子操作的是如何实现的

**处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。**

所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。

第二个机制是通过缓存锁定来保证原子性。频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁。在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为**缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能使用同时缓存i的缓存行。**

## Java的注解？

Annotation其实是一种接口。通过Java的反射机制相关的API来访问Annotation信息（比如参数）。相关类（框架或工具中的类）根据这些信息来决定如何使用该程序元素或改变它们的行为。Java语言解释器在工作时会忽略这些Annotation，因此在JVM中这些Annotation是“不起作用”的，只能通过配套的工具才能对这些Annotation类型的信息进行访问和处理。Annotation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的申明语句中。

### 和interface的异同：

-  annotition的类型使用关键字@interface而不是interface。它继承了java.lang.annotition.Annotition接口，并非申明了一个interface。
- Annotation类型、方法定义是独特的、受限制的。Annotation类型的方法必须申明为无参数、无异常抛出的。

## JDK中NIO有哪些重要组件？

### Channel

JavaNIO Channels和流有一些相似，但是又有些不同：

- 你可以同时读和写Channels，流Stream只支持单向的读或写（InputStream/OutputStream）
- Channels可以异步的读和写，流Stream是同步的
- Channels总是读取到buffer或者从buffer中写入

### Buffer

在Java NIO中各类Buffer主要用于和NIO Channel进行交互，数据从Channel中读取到Buffer中，从Buffer写入到Channel中。

![img](https://upload-images.jianshu.io/upload_images/1429695-bdc6598cd7d19d4d?imageMogr2/auto-orient/strip|imageView2/2/w/338/format/webp)

我们可以将Buffer看做内存中的一块区域，我们可以在这块区域上写数据，然后在从中读取。这块内存区域被包装成NIO Buffer对象，提供了一系列的方法使我们操作这块内存变得更简单一些。

Buffer对象使用**capacity**，**position**，**limit**三个属性来保存内存状态以便灵活操作内存，了解这三个属性的作用是理解Buffer工作原理的关键。**position**和**limit**决定了Buffer可以读写的区域（position <= x < limit），**capacity** 表示读写的最大容量。在写数据的时候，limit限制了写入数据的最大容量即position的最大值（position < limit）.在写模式下，limit=capacity；

![img](https://upload-images.jianshu.io/upload_images/1429695-c8a83b518957c68e?imageMogr2/auto-orient/strip|imageView2/2/w/506/format/webp)

### Selector

Selector是Java NIO中用于管理一个或多个Channel的组件，控制决定对哪些Channel进行读写；通过使用Selector让一个单线程可以管理多个Channel甚至多个网络连接。

使用Selector最大的优势就是可以在较少的线程中控制更多的Channel。事实上我们可以使用一个线程控制需要使用的所有Channel。操作系统线程的运行和切换需要一定的开销，使用的线程越小，系统开销也就越少；因此使用Selector可以节省很多系统开销。下图展示了一个线程使用Selector控制三个Channel的情形。

![img](https://upload-images.jianshu.io/upload_images/1429695-2b4f583d6a1d8a0c?imageMogr2/auto-orient/strip|imageView2/2/w/408/format/webp)

## innodb中一颗B+树能存储多少条数据

InnoDB存储引擎的最小存储单元为16k（就像操作系统的最小单元为4k 即1页），在这即B+树的一个节点的大小为16k 

假设数据库一条数据的大小为1k，则一个节点可以存储16条数据

而非叶子节点，key一般为主键假设8字节，指针在InnoDB中是6字节，一共为14字节，一个节点可以存储 16384/14 = 1170个索引指针

 可以算出一颗高度为2的树（即根节点为存储索引指针节点，还有1170个叶子节点存储数据），每个节点可以存储16条数据，一共1170*16条数据 = 18720条

高度为3的树，可以存放 1170 * 1170 * 16 = 21902400条记录

两千多万条数据，我们只需要B+树为3层的数据结构就可以完成，通过主键查询只需要3次IO操作就能查到对应记录。

## String的hashCode方法

```java
public int hashCode() {
    int h = hash;
    if (h == 0 && value.length > 0) {
        char val[] = value;

        for (int i = 0; i < value.length; i++) {
            h = 31 * h + val[i];
        }
        hash = h;
    }
    return h;
}
```

在String类中有个私有实例字段hash表示该串的哈希值，在第一次调用hashCode方法时，字符串的哈希值被计算并赋值给hash字段，之后再调用hashCode方法便可以直接取hash字段返回。相当于缓存。

String类中的hashCode计算方法还是比较简单的，就是以31为权，每一位为字符的ASCII值进行运算，用自然溢出来等效取模。

哈希计算公式可以计为val[0]\*31^(n-1) + val[1]*31^(n-2) + ... + val[n-1]  

**`为什么是31？`**

- 31 是一个素数，与素数相乘得到的结果比其他方式更容易产生唯一性。
- 31 的二进制为： 11111，占用 5 个二进制位，在进行乘法运算时，`31*i=32*i-i=(i<<5)-i`。这种位移与减法结合的计算相比一般的运算快很多。

## TCP状态TIME_WAIT 过多的处理

原因是服务端主动关闭，服务端要等待2MSL。这样会占用很多个端口，无法进行新的TCP连接。

`net.ipv4.tcp_tw_reuse = 1`在Linux中可以开启重用，允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；

`net.ipv4.tcp_tw_recycle = 1`表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。

## 零拷贝

### DMA

DMA 全称叫直接内存存取（Direct Memory Access），是一种允许外围设备直接访问系统主存的机制。CPU 通知 DMA 控制器拷贝外部存储设备数据到内核缓冲区，完成后再通知 CPU 拷贝到用户缓冲区。和 I/O 中断方式相比，改由内存来执行外部存储器数据的 I/O 操作，减轻了CPU负担，且 CPU 读取内存比读取外部存储设备速度要快。

------

`零拷贝`是基于 DMA 的, 其目的就是优化多次数据拷贝的过程，避免 CPU 将数据从一块存储拷贝到另外一块存储。有 3 个实现思路：

1. 用户态直接 I/O : 应用程序直接访问硬件存储，内核只辅助数据传输。硬件上的数据直接拷贝给用户空间，也就不存在内核空间缓冲区和用户空间缓冲区间的数据拷贝了。
2. 减少数据拷贝次数：在数据传输过程中，减少数据在用户空间缓冲区和系统内核空间缓冲区之间的 CPU 拷贝次数，同时也避免数据在内核空间内部的 CPU 拷贝。
3. 写时复制：多个进程共享同一块数据时，如果某进程要对这份数据修改，那将其拷贝到自己的进程地址空间中。

传统IO，在进行一次读写时共涉及了4次上下文切换，2次 DMA 拷贝以及2次 CPU 拷贝。

![img](D:\Typora\picture\screen-1535441.png)

### 用户态直接IO

这是第一种思路，使应用进程或处于用户态下的库函数跨过内核直接访问硬件，内核在数据传输过程除了进行必要的虚拟存储配置工作外，不参与任何其他工作。

![img](http://img.llc687.top/uPic/screen-1535947.png)

但只适用于不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，又称为自缓存应用程序，如数据库管理系统。其次，因 CPU 和磁盘 I/O 之间的性能差距，就会造成资源的浪费，一般是会配合异步 I/O 使用。

### mmap

这属于第二类优化，减少了 1 次 CPU 拷贝。MMAP 是数据不会到达用户空间内存，只会存在于系统空间的内存上，用户空间与系统空间共用同一个缓冲区，两者通过映射关联。

![img](http://img.llc687.top/uPic/screen-1773287.png)

整个 MMAP 过程，发生了 4 次上下文切换 + 1 次 CPU 拷贝 + 2 次 DMA 拷贝。

### sendfile

这也是第二类优化。用户进程不需要单独调用 read/write ，而是直接调用 sendfile() ，sendfile 再帮用户调用 read/write 操作。数据可以直接在内核空间进行 I/O 传输，省去了数据在用户空间和内核空间之间的拷贝。

与 mmap 内存映射方式不同的是， sendfile() 调用中数据对用户空间是完全不可见的。也就是说，这是一次完全意义上的数据传输过程。

![img](http://img.llc687.top/uPic/image-20200610154454498.png)

整个过程发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。

### sendfile + DMA gather copy

在前面的 sendfile() 方式中，CPU 仍需要一次拷贝，从 Linux 2.4 版本开始，DMA 自带了收集功能，可以将对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket buffer），由DMA 根据这些信息直接将内核缓冲区的数据拷贝到网卡设备中，省下了最后一次 CPU 拷贝。

![img](http://img.llc687.top/uPic/image-20200610154613272.png)

这次只发生 2 次上下文切换 + 2 次 DMA 数据拷贝。

### 写时复制

这个就是第三种思路了，COW 写时复制。

当用户进程有写操作时，就把这块共享的内存空间复制一份到其他区域，给写进程专用。这种方法在能够降低系统开销，如果某个进程永远不会对数据进行更改，那就永远不需要拷贝。

## xss、csrf

### XSS

跨站脚本攻击是指恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。

防范方法可以是：

- 过滤。对诸如<script>、<img>、<a>等标签进行过滤。
- 编码。像一些常见的符号，如<>在输入的时候要对其进行转换编码，这样做浏览器是不会对该标签进行解释执行的，同时也不影响显示效果。
- 限制。xss攻击要能达成往往需要较长的字符串，因此对于一些可以预期的输入可以通过限制长度强制截断来进行防御。

### CSRF

XSS利用的是站点内的信任用户，CSRF是通过伪装来自受信任用户的请求来利用受信任的网站。你可以这么理解CSRF攻击：攻击者盗用了你的身份，以你的名义向第三方网站发送恶意请求。 CRSF能做的事情包括利用你的身份发邮件、发短信、进行交易转账等，甚至盗取你的账号。

防范方法：

- 尽量使用post，限制get。GET接口太容易被拿来做CSRF攻击，看上面示例就知道，只要构造一个img标签，而img标签又是不能过滤的数据。接口最好限制为POST使用，GET则无效，降低攻击风险。
- 将cookie设置为HttpOnly。CRSF攻击很大程度上是利用了浏览器的cookie，为了防止站内的XSS漏洞盗取cookie,需要在cookie中设置“HttpOnly”属性，这样通过程序（如JavaScript脚本、Applet等）就无法读取到cookie信息，避免了攻击者伪造cookie的情况出现。
- 增加token。CSRF攻击之所以能够成功，是因为攻击者可以伪造用户的请求，该请求中所有的用户验证信息都存在于cookie中，因此攻击者可以在不知道用户验证信息的情况下直接利用用户的cookie来通过安全验证。由此可知，抵御CSRF攻击的关键在于：**在请求中放入攻击者所不能伪造的信息，并且该信总不存在于cookie之中**。鉴于此，系统开发人员可以在HTTP请求中以参数的形式加入一个随机产生的token，并在服务端进行token校验，如果请求中没有token或者token内容不正确，则认为是CSRF攻击而拒绝该请求。
- 通过Referer识别。在HTTP头中有一个字段叫Referer，它记录了该HTTP请求的来源地址。在通常情况下，访问一个安全受限的页面的请求都来自于同一个网站。比如某银行的转账是通过用户访问`http://www.xxx.com/transfer.do`页面完成的，用户必须先登录`www.xxx.com`，然后通过单击页面上的提交按钮来触发转账事件。当用户提交请求时，该转账请求的Referer值就会是
   提交按钮所在页面的URL

## SQL注入

SQL注入，是利用web程序的请求，构建特殊的输入参数，将恶意的SQL语句注入到后台数据库引擎中，最终可以欺骗服务器执行恶意SQL。

可以通过预编译防止sql注入

PreparedStatement和Statement最大的区别在于，前者会提前将SQL发送给数据库进行预编译，提前确定了执行计划，对于输入的参数，无论是什么，都会按照原先的计划进行填入执行，不会再改变SQL的逻辑结构；而后者则会随着输入参数的不同改变SQL逻辑结构，因此有注入的风险。

如果没有预编译，那么每次在执行这些SQL的时候，数据库都需要进行词法分析、语义分析、制定执行计划、执行并返回结果这些操作，比较耗时和耗费资源。因此，数据库有一种机制可以将这些结构相同的SQL进行预编译，形成固定的执行计划，下次再执行的时候，直接拿这些执行计划，套入传入的参数执行即可，大大提高了效率。



如果是不能预编译的场景，那么需要对输入参数采取类型检查、转义映射、安全过滤等措施。

## Lambda表达式实现原理

采用的是内部类来实现的

- 生成一个静态方法，方法内容就是lambda表达式内容
- 生成一个匿名内部类，在这个类里调用1中生成的静态方法
- 在使用lambda表达式的地方，通过传递内部类实例，来调用函数式接口方法

## MySQL服务端架构

1.数据库管理系统（最外层）：DBMS，专门管理服务器端的所有内容
2.数据库（第二层）：DB，专门用于存储数据的仓库（可以有很多个）
3.二维数据表（第三层）：Table，专门用于存储具体实体的数据
4.字段（第四次）：Field，具体存储某种类型的数据（实际存储单元）

## 为什么要Survivor区，为什么要两个Survivor

如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。老年代很快被填满。**Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。**



**设置两个Survivor区最大的好处就是解决了碎片化**。假设现在只有一个survivor区，我们来模拟一下流程： 
刚刚新建的对象在Eden中，一旦Eden满了，触发一次Minor GC，Eden中的存活对象就会被移动到Survivor区。这样继续循环下去，下一次Eden满了的时候，问题来了，此时进行Minor GC，Eden和Survivor各有一些存活对象，如果此时把Eden区的存活对象硬放到Survivor区，很明显这两部分对象所占有的内存是不连续的，也就导致了内存**碎片化**。

如果分为两块，**永远有一个survivor space是空的，另一个非空的survivor space无碎片**。

## HTTP通信传输细节

![img](https://upload-images.jianshu.io/upload_images/8608648-69d30e24bc9b7fca.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

## TCP 长连接

当一个 TCP 连接建立之后，启用 TCP Keepalive 的一端便会启动一个计时器，当这个计时器数值到达 0 之后（也就是经过tcp_keep-alive_time时间后），一个 TCP 探测包便会被发出。这个 TCP 探测包是一个纯 ACK 包（规范建议，不应该包含任何数据，但也可以包含1个无意义的字节，比如0x0。），其 Seq号 与上一个包是重复的，所以其实探测保活报文不在窗口控制范围内。

如果一个给定的连接在两小时内（默认时长）没有任何的动作，则服务器就向客户发一个探测报文段，客户主机必须处于以下4个状态之一：

1.     客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常的，服务器在两小时后将保活定时器复位。

2.     客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应。服务端将不能收到对探测的响应，并在75秒后超时。服务器总共发送10个这样的探测 ，每个间隔75秒。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。

3.     客户主机崩溃并已经重新启动。服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。

4.     客户机正常运行，但是服务器不可达，这种情况与2类似，TCP能发现的就是没有收到探测的响应。


### TCP Keepalive HTTP Keep-Alive 的关系

HTTP协议的Keep-Alive意图在于TCP连接复用，同一个连接上串行方式传递请求-响应数据；TCP的Keepalive机制意图在于探测连接的对端是否存活。